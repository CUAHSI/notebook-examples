{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b469fd7b-c0ad-48a2-9d7d-a7f1bf0658db",
   "metadata": {},
   "source": [
    "## Comparing Basin Averaged AORC and PRISM Precipitation for the Logan River Watershed \n",
    "\n",
    "**Authors**:  \n",
    "- Tony Castronova <acastronova@cuahsi.org>  \n",
    "- Irene Garousi-Nejad <igarousi@cuahsi.org>  \n",
    "\n",
    "**Last Updated**: 05.08.2023\n",
    "\n",
    "**Description**:  \n",
    "\n",
    "This notebook compares AORC v1.1 and PRISM precipitation estimates for the Logan River watershed in Logan, Utah. AORC (version 1.1) forcing data is collected  from HydroShare's THREDDS server and subset for the Logan River watershed. PRISM data has been prepared in advance and stored in a HydroShare [resource](https://www.hydroshare.org/resource/709bc880194046e3b79b0da56ad090fa/).\n",
    "\n",
    "*Analysis of Record for Calibration (AORC)*  \n",
    "> The Analysis of Record for Calibration (AORC) is a gridded record of near-surface weather conditions covering the continental United States and Alaska and their hydrologically contributing areas. It is defined on a latitude/longitude spatial grid with a mesh length of ~800 m (30 arc seconds), and a temporal resolution of one hour. Elements include hourly total precipitation, temperature, specific humidity, terrain-level pressure, downward longwave and shortwave radiation, and west-east and south-north wind components. It spans the period from 1979 at Continental U.S. (CONUS) locations / 1981 in Alaska, to the near-present (at all locations). This suite of eight variables is sufficient to drive most land-surface and hydrologic models and is used to force the calibration run of the National Water Model (NWM).\n",
    "\n",
    "*Parameter-elevation Regressions on Independent Slopes Model (PRISM)*\n",
    "> The PRISM Climate Data from Oregon State University is a gridded product covering the Conterminous United States. It combines climate observations from a wide range of monitoring networks with sophisticated modeling techniques to establish a local climate-elevation relationship for each grid cell. This relationship is then utilized to estimate various climate variables such as precipitation. This dataset spans from 1895 to the present and can be used to analyze short- and long-term climate patterns. The PRISM dataset is widely used across multiple disciplines, such as hydrology, climatology, agriculture, and environmental sciences and its popularity stems from its high spatial resolution, long-term record, reliable data quality, and ease of accessibility. It is worth noting that the PRISM dataset is available at two distinct spatial scales. The 4 km version is accessible to the public, while a more refined 800 m resolution dataset is available for a fee. For our purposes, we will be utilizing the publicly available 4 km resolution dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb6e0261-0fd8-4011-bce8-90598fb8dc44",
   "metadata": {},
   "source": [
    "**Software Requirements**\n",
    "\n",
    "This notebook was developed using the following software and operating system versions.\n",
    "\n",
    "OS: MacOS Ventura 13.0.1  \n",
    "> Python: 3.11.0   \n",
    "netcdf4: 1.6.3   \n",
    "xarray: 2023.4.2   \n",
    "dask: 2023.4.1      \n",
    "distributed: 2023.4.1    \n",
    "matplotlib: 3.7.1  \n",
    "pandas: 2.0.1    \n",
    "cartopy: 0.21.1  \n",
    "fiona: 1.9.3  \n",
    "geopandas: 0.13.0    \n",
    "rioxarray: 0.14.1  \n",
    "\n",
    "OS: Microsoft Windows 11 Pro version 10.0.22621\n",
    "> Python: 3.11.2   \n",
    "netcdf4: 1.6.3   \n",
    "xarray: 2022.11.0 \n",
    "dask: 2023.3.2    \n",
    "distributed: 2023.3.2    \n",
    "matplotlib: 3.7.1  \n",
    "pandas: 1.5.3    \n",
    "cartopy: 0.21.1  \n",
    "fiona: 1.9.1  \n",
    "geopandas: 0.12.2   \n",
    "rioxarray: 0.14.0  \n",
    "ipywidgets: 8.0.4\n",
    "\n",
    "\n",
    "The following commands should help you set up these dependencies\n",
    "```\n",
    "$ conda create -n nwm-env python=3.10.0\n",
    "\n",
    "$ conda install -y -c pyviz -c conda-forge pynhd folium s3fs hvplot dask distributed zarr\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c4dadef-1b89-4fa5-bac5-89baa70c2f51",
   "metadata": {},
   "source": [
    "## 1. Search AORC Forcing on HydroShare Thredds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f473a255-3a76-43e2-8251-9c859182994d",
   "metadata": {},
   "source": [
    "The AORC Forcing data used in this notebook covers the Great Basin watershed from 2010-2019 and is stored in HydroShare's Thredds catalog:\n",
    "\n",
    "https://thredds.hydroshare.org/thredds/catalog/aorc/data/v1.1/16/catalog.html\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb325c4-329d-494b-a1eb-9a439b5bc5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy\n",
    "import pyproj\n",
    "import xarray\n",
    "import pandas\n",
    "import requests\n",
    "import geopandas\n",
    "import rioxarray \n",
    "import cartopy.crs as ccrs\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as ET\n",
    "from shapely.geometry import MultiPolygon\n",
    "from cartopy.io.shapereader import Reader\n",
    "from cartopy.feature import ShapelyFeature"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa93bf04-9f1a-41f0-84bd-aab3807da600",
   "metadata": {},
   "source": [
    "Initialize a `dask` distributed local cluster. This is not required but is used to speed up computations by distributing tasks across multiple workers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b40f285-867a-4664-b525-0ebb463d7f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ae87a46a-f385-49ce-9b4e-1e3720adbc63",
   "metadata": {},
   "source": [
    "### 1. Read AORC Data from HydroShare Thredds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81f63ef6-1d24-41bd-9681-9d62829fad6c",
   "metadata": {},
   "source": [
    "To discover the available data, we're reading an XML file and parsing its content. Using this information we create a list of URLs that can be loaded using `xarray` in later steps. This process is optional and can be bypassed by manually collecting these urls from the THREDDs interface via web browser. \n",
    "\n",
    "Identify the files in the catalog via the catalog.xml document. The following link provides a list of all available data for the HUC-2 region for the Great Basin; `HUC=16`. \n",
    "https://thredds.hydroshare.org/thredds/catalog/aorc/data/16/catalog.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb15f448-6022-4db4-be70-a3c8d8ff91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_base_url = 'https://thredds.hydroshare.org/thredds/catalog'\n",
    "dods_base_url = 'https://thredds.hydroshare.org/thredds/dodsC'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a9a4ca4-aa26-46ae-8f1b-eefb819a0872",
   "metadata": {},
   "source": [
    "Read the catalog.xml document and extract all `urlPath` attributes. We'll use the `urlPath` attribute to build the complete path to each file we want to access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a9ab4-a463-4081-a1a6-0c522f07c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = f'{catalog_base_url}/aorc/data/v1.1/16/catalog.xml'\n",
    "root = ET.fromstring(requests.get(url).text)\n",
    "ns = '{http://www.unidata.ucar.edu/namespaces/thredds/InvCatalog/v1.0}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c85698f-43c5-48f1-8d70-8ec43a9771b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use xpath top select all \"dataset\" elements.\n",
    "elems = root.findall(f'.//{ns}dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e130df3d-a208-4ddf-add5-f54ad37c257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through results and extract the \"urlPath\" attribute values\n",
    "paths = []\n",
    "for elem in elems:\n",
    "    atts = elem.attrib\n",
    "    if 'urlPath' in atts.keys():\n",
    "        paths.append(f\"{dods_base_url}/{atts['urlPath']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b80efb-c3ac-42cb-95a5-7f33fd284691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use regex to isolate only files that end with \".nc\"\n",
    "paths = list(filter(re.compile(\"^.*\\.nc$\").match, paths))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d2f2c6f1-6c4a-4367-a3db-6db534a69243",
   "metadata": {},
   "source": [
    "Print out some information about the files that we've found. For example, the total number of files as well as the names for the first and last files. The names of the first and last files will give us the temporal range of data that's available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9153310-25b5-4472-8bbb-09928fbc4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Found {len(paths)} individual files')\n",
    "print(f'The first file is named: {os.path.basename(paths[0])}')\n",
    "print(f'The last file is named: {os.path.basename(paths[-1])}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c95d5bb7-9bad-4a31-9b92-ae8cf52a47c6",
   "metadata": {},
   "source": [
    "Connect to the THREDDs server and load a single month of data to explore that variables and spatial extent that is available to us. Using the URLs stored in the `paths` variable, we can load the first file via index 0 (i.e. `paths[0]`):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df34c9-ccb5-4a5a-a202-c8d697bff2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = xarray.open_mfdataset(paths,\n",
    "                           concat_dim='time',\n",
    "                           combine='nested',\n",
    "                           parallel=True,\n",
    "                           chunks={'time': 10, 'x': 285, 'y':275},\n",
    "                           engine='netcdf4')\n",
    "\n",
    "X, Y = numpy.meshgrid(ds.x.values, ds.y.values)\n",
    "\n",
    "# define the input crs\n",
    "wrf_proj = pyproj.Proj(proj='lcc',\n",
    "                       lat_1=30.,\n",
    "                       lat_2=60., \n",
    "                       lat_0=40.0000076293945, lon_0=-97., # Center point\n",
    "                       a=6370000, b=6370000) \n",
    "\n",
    "# define the output crs\n",
    "wgs_proj = pyproj.Proj(proj='latlong', datum='WGS84')\n",
    "\n",
    "# transform X, Y into Lat, Lon\n",
    "transformer = pyproj.Transformer.from_crs(wrf_proj.crs, wgs_proj.crs)\n",
    "lon, lat = transformer.transform(X, Y)\n",
    "\n",
    "ds = ds.assign_coords(lon = (['y', 'x'], lon))\n",
    "ds = ds.assign_coords(lat = (['y', 'x'], lat))\n",
    "\n",
    "\n",
    "# add crs to netcdf file\n",
    "ds.rio.write_crs(ds.crs.attrs['spatial_ref'], inplace=True\n",
    "                ).rio.set_spatial_dims(x_dim=\"x\",\n",
    "                                       y_dim=\"y\",\n",
    "                                       inplace=True,\n",
    "                                       ).rio.write_coordinate_system(inplace=True)\n",
    "\n",
    "\n",
    "# make sure the data is sorted by time\n",
    "ds = ds.sortby('time')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa009767-6c00-43b4-b2a6-ed6a57d5d635",
   "metadata": {},
   "source": [
    "## 2. Preview the AORC Forcing Data Covering the Great Basin\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8b11c0ba-79b6-4eb0-b2a4-f099de07e46a",
   "metadata": {},
   "source": [
    "Display the variables that are contained in this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6798a8e0-443c-4547-814f-a6afd07433a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c165e32-4847-4a88-bd72-96ded68c58fd",
   "metadata": {},
   "source": [
    "Plot the `RAINRATE` variable for the first timestep across the entire grid domain. There are numerous ways to select data within an Xarray DataSet, for more information on see: https://docs.xarray.dev/en/stable/user-guide/indexing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc28095-38ae-4736-8689-f1af76f518af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot RAINRATE for the entire spatial grid at time=0\n",
    "ds.isel(time=0).RAINRATE.plot(figsize=(10, 10));"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e2898bc6-9e2e-46aa-8b2b-f24c37341af0",
   "metadata": {},
   "source": [
    "Load the Logan River Watershed shapefile using the `ShapelyFeature` function from the `Cartopy` Python package and preview it over the incoming longwave radiation (`LWDOWN`) for a single time step from AORC gridded data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef2ec77-424b-4f95-a21f-16a6ca43bad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = MultiPolygon(Reader('logan-watershed-huc12.shp').geometries())\n",
    "\n",
    "# read the geometries for plotting\n",
    "shape_feature = ShapelyFeature(mp.geoms,\n",
    "                                ccrs.PlateCarree(), facecolor='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab80046-b8a9-4e35-8a7f-daf6120abc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the shapefile over the AORC data\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_global()\n",
    "\n",
    "# plot LWDOWN at the first timesteop\n",
    "ds.isel(time=1).LWDOWN.plot(\n",
    "               ax=ax, transform=ccrs.PlateCarree(), x=\"lon\", y=\"lat\",\n",
    "               zorder=2)\n",
    "\n",
    "shape_feature = ShapelyFeature(mp.geoms,\n",
    "                                ccrs.PlateCarree(), facecolor='none')\n",
    "ax.add_feature(shape_feature, zorder=10)\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=2, color='gray', alpha=0.5, linestyle='--');\n",
    "\n",
    "# adjust the map boundary\n",
    "xmin, ymin, xmax, ymax = mp.bounds\n",
    "dx, dy = (0.1, 0.05)\n",
    "ax.set_ylim([ymin - dy, ymax + dy]);\n",
    "ax.set_xlim([xmin - dx, xmax + dx]);\n",
    "\n",
    "ax.set_aspect('equal');\n",
    "ax.coastlines();\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "348c8a81-c9c3-4a8d-aad7-9ba622ad6785",
   "metadata": {},
   "source": [
    "## 2. Subset AORC to the Logan River Watershed.\n",
    "\n",
    "The obtained AORC data encompasses the Great Basin region, which exceeds the size of the Logan River watershed. To narrow down the data to our desired spatial extent, we will utilize the watershed shapefile for subsetting.  It is crucial to verify that both the AORC dataset and the watershed shapefile share the smae projected coordinate system. This alignment is essential to ensure accurate and reliable subsetting of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6713ba-cab7-43f6-8f00-269ad4fee292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the geopandas packate to read the watershed shapefile and to prepare geometries for spatial averaging \n",
    "gdf = geopandas.read_file('logan-watershed-huc12.shp')\n",
    "\n",
    "# define a target coordinate system and convert the geometry data into the projection of our forcing data\n",
    "target_crs = pyproj.Proj(proj='lcc',\n",
    "                       lat_1=30.,\n",
    "                       lat_2=60., \n",
    "                       lat_0=40.0000076293945, lon_0=-97., # Center point\n",
    "                       a=6370000, b=6370000) \n",
    "\n",
    "gdf = gdf.to_crs(target_crs.crs)\n",
    "\n",
    "# use rioxarray to clip the gridded AORC to the watershed boundary.\n",
    "ds = ds.rio.clip(gdf.geometry.values,\n",
    "                 gdf.crs,\n",
    "                 drop=True,\n",
    "                 invert=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ebae718c-1151-43a8-a448-1a60b25cc3bb",
   "metadata": {},
   "source": [
    "Plot the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41480a03-233c-48df-8211-60714344cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the subset using cartopy\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.set_global()\n",
    "\n",
    "shape_feature = ShapelyFeature(mp.geoms,\n",
    "                                ccrs.PlateCarree(), facecolor='none')\n",
    "ax.add_feature(shape_feature, zorder=1)\n",
    "\n",
    "# plot LWDOWN at the first timesteop\n",
    "ds.isel(time=1).LWDOWN.plot(\n",
    "      ax=ax, transform=ccrs.PlateCarree(), x=\"lon\", y=\"lat\",\n",
    "     zorder=0)\n",
    "\n",
    "gl = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=2, color='gray', alpha=0.5, linestyle='--');\n",
    "ax.set_ylim([41.70, 42.10]);\n",
    "ax.set_xlim([-111.80, -111.45]);\n",
    "ax.set_aspect('equal');\n",
    "ax.coastlines();"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "779ef838-2a19-4e3b-9205-52225a3c0b7f",
   "metadata": {},
   "source": [
    "## 3. Compute the Spatial Average Daily Precipitation across the Watershed"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5621bdd5-75c2-47d0-9734-d25d44db0f99",
   "metadata": {},
   "source": [
    "We will now focus on the first three months of the water year 2011 (i.e., starting on Oct 1, 2010 to the end of Dec 2010) and then partition the data into smaller pieces using the `chunk` function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee53f06-8f35-4325-906b-36ecba43ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the start and end dates for the period of interest and subset the data\n",
    "st = '2010-10-01'\n",
    "et = '2010-12-31'\n",
    "data = ds.RAINRATE.loc[dict(time=slice(st, et))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e7eb676-916a-483a-a0ed-da307fbc9bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunck the dataset automatically based on the available system resources and data size. \n",
    "data = data.chunk(chunks='auto')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e9700661-62e5-459f-a466-a90a1832b19f",
   "metadata": {},
   "source": [
    "Let's collect the subset of data we obtained above into memory before we do an additional processing to ensure that computations on the data variable are optimized for performance. The following cell uses `Dask` (a parallel computing library) to persist and monitor the progress of our computation. The `.persist()` operation tells `Dask` to keep the data in memory and persist it across the cluster if one is available. By persisting the data, subsequent computations can be performed more efficiently, as the data is readily **available in memory**. The `progress()` function creates a progress bar that displays the status of the ongoing computations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7509ec-8cee-4a3f-905f-d2b37fb39ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import progress\n",
    "d = data.persist()\n",
    "progress(d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "395a9d00-8cc0-4eea-b94b-930d7b7aed16",
   "metadata": {},
   "source": [
    "Now, we will compute the spatially averaged daily precipitation by processing the gridded hourly precipitation rates. This task involves three steps: (1) resampling the hourly data to obtain daily total, (2) subsequently computing the average over the spatial dimension, and (3) covert units from $mm/s$ to $mm/day$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7357ca57-0a71-4182-bacc-a5b5e3c1ff9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "basin_ave_precip = d.resample(time='1D').sum().mean(dim=['x','y']) * 3600"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "80e43321-04bd-4f2a-9fd3-70520a877dcb",
   "metadata": {},
   "source": [
    "## 4. Compare the AORC precipitation data with the PRISM precipitation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55783961-2def-4f08-bfe0-65e05c742f08",
   "metadata": {},
   "source": [
    "PRISM data was downloaded from HydroShare. Let's load these data using `Pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3a190e-575e-4907-8b47-a3a768d8912a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('Daily_PRISM_Precipitation_in_2010_for_LoganRiverWatershed.csv')\n",
    "df['Date'] = pandas.to_datetime(df.Date)\n",
    "df.set_index('Date', inplace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8eeb1534-7c02-4fd9-ba50-5b3336e42b4e",
   "metadata": {},
   "source": [
    "Compare AORC and PRISM daily precipitation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5eb46d-ebcd-4a4e-ac60-dee1b7d4f199",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(basin_ave_precip.time, basin_ave_precip.cumsum(), label='AORC v1.1', color='k');\n",
    "\n",
    "df[slice(st, et)]['Precipitation (mm)'].cumsum().plot(ax=ax, label='PRISM', color='b')\n",
    "\n",
    "ax.set_ylabel('Daily Precipitation (mm)');\n",
    "ax.set_xlabel('Date');\n",
    "fig.suptitle('Comparison of AORC and PRISM Cumulative Daily Precipitation for the Logan River Watershed');\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd251eb9-4e63-45fd-9afc-45a03ff01f2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo-cartopy",
   "language": "python",
   "name": "geo-cartopy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
