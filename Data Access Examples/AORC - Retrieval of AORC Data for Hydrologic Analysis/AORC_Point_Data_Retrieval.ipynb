{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db250eac-dd32-4895-88bb-72ccbb8f5ca2",
   "metadata": {},
   "source": [
    "# Retrieving and Aggregating AORC Data at a Point"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1958827-496d-44a2-9b2d-ba557c8fb0fa",
   "metadata": {},
   "source": [
    "**Authors:** \n",
    "\n",
    "<ul style=\"line-height:1.5;\">\n",
    "<li>Ayman Nassar <a href=\"mailto:ayman.nassar@usu.edu\">(ayman.nassar@usu.edu)</a></li>\n",
    "<li>Pabitra Dash <a href=\"mailto:pabitra.dash@usu.edu\">(pabitra.dash@usu.edu)</a></li>\n",
    "<li>Homa Salehabadi <a href=\"mailto:homa.salehabadi@usu.edu\">(homa.salehabadi@usu.edu)</a></li>\n",
    "<li>David Tarboton <a href=\"mailto:david.tarboton@usu.edu\">(david.tarboton@usu.edu)</a></li>\n",
    "<li>Anthony Castronova <a href=\"acastronova@cuahsi.org\">(acastronova@cuahsi.org)</a></li>\n",
    "\n",
    "</ul>\n",
    "\n",
    "**Last Updated:** 1/20/2025\n",
    "\n",
    "**Purpose:**\n",
    "\n",
    "This notebook provides code examples for retrieving NOAA Analysis of Record for Calibration (AORC) data from Amazon Web Services (AWS). It is intended to make it easy for researchers to access data for a specific point specified by latitude and longitude or known geographic coordinates. It also allows for data aggregation at time scales different from the underlying NOAA data.\n",
    "\n",
    "**Audience:**\n",
    "\n",
    "Researchers who are familiar with Jupyter Notebooks, basic Python and basic hydrologic data analysis.\n",
    "\n",
    "**Description:**\n",
    "\n",
    "This notebook takes as inputs the coordinates (e.g. latitude and longitude) of a study location in any coordinate system, start and end dates for the desired study period, a variable name, and a preferred time aggregation interval. It then retrieves data from Amazon Web Services (AWS), aggregates it over the specified time interval, displays the data as a plot, and saves it as a comma separated variable (CSV) file.\n",
    "\n",
    "**Data Description:**\n",
    "\n",
    "This notebook uses AORC data developed and published by NOAA on Amazon Web Services (AWS) as described in detail in this registry of open data entry <https://registry.opendata.aws/noaa-nws-aorc/>. The AORC dataset is a gridded record of near-surface weather conditions covering the continental United States and Alaska and their hydrologically contributing areas. It is defined on a latitude/longitude spatial grid with a mesh length of 30 arc seconds (~800 m), and a temporal resolution of one hour. This notebook uses the Zarr format files of version 1.1 of the AORC data. Zarr is a format for storage of chunked, compressed, N-dimensional arrays, designed to support storage using distributed systems such as cloud object stores (<https://zarr.dev/>).\n",
    "\n",
    "\n",
    "**Software Requirements:**\n",
    "\n",
    "This notebook has been tested on the CIROH Jupyterhub, CyberGIS Jupyter for Water and CUAHSI JupyterHub deployments. It relies on a general-purpose Jupyter computing environment with the following specific Python libraries: \n",
    "\n",
    " > numpy: 1.26.4     \n",
    "   geopandas: 0.14.3  \n",
    "   pandas: 2.2.1  \n",
    "   matplotlib: 3.8.3   \n",
    "   contextily: 1.6.2    \n",
    "   shapely: 2.0.3\n",
    "\n",
    "It also uses code from aorc_utils.py that accompanies this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008462b4-5ebb-4b85-b513-082c52e64f68",
   "metadata": {},
   "source": [
    "### 1. Install and Import Python Libraries Needed to Run this Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bd810b-9a55-4da7-8ce8-2089c8209abf",
   "metadata": {},
   "source": [
    "The `contextily` library is used in this notebook for mapping. It may not be installed in your Python environment by default so should be installed before you work with it. Use the following command to install the contextily library:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b83a7ff-0e3d-4d8f-be62-66b2a12c9bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install contextily"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e432edb-4811-4b24-841a-2a61dc93bf3a",
   "metadata": {},
   "source": [
    "Import the libraries needed to run this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d61a5-bf09-4b2d-930f-b1bf944fa411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import contextily as ctx  # For adding a basemap\n",
    "from shapely.geometry import Point\n",
    "from aorc_utils import get_conus_bucket_url, load_dataset, reproject_coordinates, get_variable_code, get_aggregation_code, get_time_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63434088-5ea0-4eef-a2f0-3521b0e49cad",
   "metadata": {},
   "source": [
    "### 2. Set Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0857572-0a64-496a-8d57-b585ecc5417d",
   "metadata": {},
   "source": [
    "Use the cells in this section of the notebook to set the input values that specify the data to retrieve. The coordinate system for the point latitude (or y) and longitude (or x) coordinates needs to be given, using an European Petroleum Survey Group (EPSG) code.  EPSG codes are a widely used coordinate system encoding and are given at [https://spatialreference.org/](https://spatialreference.org/). The specific EPSG value of 4326 given in the cell below references the World Geodetic System of 1984 (WGS84) geographic latitude and longitude coordinate system. Thus the input lon and lat values are interpreted as being in this coordinate system. If your data is in a different coordinate system, you need to look up its EPSG code at the website above and use it in the cell below.  To learn more about coordinate systems, see, for example, the [UCGIS body of Knowledge section on Coordinate Systems](https://gistbok-topics.ucgis.org/DM-05-047)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cc77e5-70cd-483e-807e-dfbab644c2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start date - In Year-Month-Day format, the earliest start date can be '1979-02-01'\n",
    "start_datetime = '1990-01-01'\n",
    "\n",
    "# End date - In Year-Month-Day format, the latest end date can be '2023-01-31'\n",
    "end_datetime = '1990-12-31'\n",
    "\n",
    "# Coordinate system EPSG code (from https://spatialreference.org/).\n",
    "input_crs = 'EPSG:4326'\n",
    "\n",
    "# Point location\n",
    "# lon, lat are used as names, even for projected coordinate systems where lon = x and lat = y\n",
    "lon = -111.96503  # Longitude or X\n",
    "lat = 40.77069  # Latitude or Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8515230-6d7d-487f-aaae-63d6a005857e",
   "metadata": {},
   "source": [
    "**The followings are valid variables to retrieve data:**\n",
    "\n",
    "- `Total Precipitation` (APCP_surface): Hourly total precipitation (kgm-2 or mm)\n",
    "- `Air Temperature` (TMP_2maboveground): Temperature (at 2 m above-ground-level (AGL)) (K)\n",
    "- `Specific Humidity` (SPFH_2maboveground): Specific humidity (at 2 m AGL) (g g-1)\n",
    "- `Downward Long-Wave Radiation Flux` (DLWRF_surface): longwave (infrared) radiation flux (at the surface) (W m-2)\n",
    "- `Downward Short-Wave Radiation Flux` (DSWRF_surface): Downward shortwave (solar) radiation flux (at the surface) (W m-2)\n",
    "- `Pressure` (PRES_surface): Air pressure (at the surface) (Pa)\n",
    "- `U-Component of Wind` (UGRD_10maboveground): (west to east) - components of the wind (at 10 m AGL) (m s-1)\n",
    "- `V-Component of Wind` (VGRD_10maboveground): (south to north) - components of the wind (at 10 m AGL) (m s-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f823cf-14f5-4245-9fa9-84bf270735e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-defined variable - see above for a list of valid variable names\n",
    "variable_name = 'Total Precipitation'\n",
    "\n",
    "# User-defined aggregation interval - valid values are 'hour','day','month','year'  \n",
    "agg_interval = 'day'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0a269-ce5f-4485-a316-f04f34f10b2d",
   "metadata": {},
   "source": [
    "### 3. Display Map with Point Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90c0559-3c85-4319-a676-4c8b8f15a5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Point location\n",
    "point = Point(lon, lat)\n",
    "\n",
    "# Create a GeoDataFrame with the point\n",
    "gdf_point = gpd.GeoDataFrame(geometry=[point], crs=input_crs)\n",
    "\n",
    "# Create a layout for the plot\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "# Display the point location\n",
    "gdf_point.plot(ax=ax, color='red', marker='o', markersize=100, label='Point Location')\n",
    "\n",
    "# Add a topographic basemap using contextily \n",
    "ctx.add_basemap(ax, source=ctx.providers.Esri.NatGeoWorldMap, crs=gdf_point.crs.to_string(), alpha=1)\n",
    "\n",
    "# Customize x and y axis labels\n",
    "ax.set_title(\"Map with Point Location\", fontsize=14)\n",
    "ax.set_xlabel(\"Longitude\", fontsize=12)\n",
    "ax.set_ylabel(\"Latitude\", fontsize=12)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a0e39e-c837-4fa5-9a36-9aa48f353ede",
   "metadata": {},
   "source": [
    "### 4. Virtually Load the Data Array \n",
    "This block of code maps the input variable and aggregation interval onto the variable encoding used in the Zarr bucket storage.  It then loads the virtual xarray dataset for the variable of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb25478-6445-43db-ab0f-6d98b42d7ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the variable code\n",
    "variable_code = get_variable_code(variable_name)\n",
    "\n",
    "# Get the S3 bucket data file URL\n",
    "url = get_conus_bucket_url(variable_code)\n",
    "ds = load_dataset(url)\n",
    "\n",
    "# Print the dataset (ds) of selected variable\n",
    "print(ds)\n",
    "\n",
    "# Print the units of the selected variable in AORC dataset\n",
    "print(f\"The unit of {list(ds.data_vars)[0]} is {ds[list(ds.data_vars)[0]].attrs.get('units', 'No units specified')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96fa2538-56d9-47c5-b851-c60a64a4ca09",
   "metadata": {},
   "source": [
    "### 5. Subset and Aggregate the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b03ba1-794a-4434-9dee-d9d615d65da1",
   "metadata": {},
   "source": [
    "This block of code first projects the input location fully specified with lon(x), lat(y) coordinates and coordinate system to the coordinate system used by the AORC data. The AORC data coordinate system is a Lambert Conformal Conic projection used by the National Water Model. Curious users could examine ds.crs.esri_pe_string to see details. \n",
    "\n",
    "Data from the AORC grid cell with center nearest to the point of interest for the variable of interest is then retrieved and aggregated to the time interval specified, using sum aggregation for precipitation and mean aggregation for other variables.  The time step of the input AORC data is hourly.\n",
    "\n",
    "The results is saved in a data frame ds_subset.df which holds as columns time (date), x and y coordinates of the AORC grid cell center nearest to the input point (in the Lambert Conformal Conic coordinate system used by AORC) and the variable of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fcb6e2-d543-4875-91ff-0e713f2c11fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproject coordinates\n",
    "x, y = reproject_coordinates(ds, lon, lat, input_crs)\n",
    "\n",
    "# Get aggregation code\n",
    "agg_code = get_aggregation_code(agg_interval)\n",
    "\n",
    "# Subsetting and aggregating the user-defined variable\n",
    "variable_code_cap = variable_code.upper()\n",
    "\n",
    "if variable_code == 'precip':\n",
    "    ds_subset = ds['RAINRATE'].loc[dict(time=slice(start_datetime, end_datetime))].sel(y=y, x=x, method='nearest').compute() * 3600\n",
    "    ds_subset_df = ds_subset.resample(time=agg_code).sum().to_dataframe()\n",
    "    unit = f\"mm/{agg_interval}\"\n",
    "else:\n",
    "    ds_subset = ds[variable_code_cap].loc[dict(time=slice(start_datetime, end_datetime))].sel(y=y, x=x, method='nearest').compute()\n",
    "    ds_subset_df = ds_subset.resample(time=agg_code).mean().to_dataframe()\n",
    "    unit = ds[variable_code_cap].attrs.get('units', 'No units specified')\n",
    "\n",
    "# Identify the column name in the resulting DataFrame\n",
    "new_column_name = ds_subset_df.columns[2]\n",
    "\n",
    "# Rename the last column to include the unit\n",
    "variable_name_with_unit = f\"{new_column_name} ({unit})\"\n",
    "ds_subset_df.rename(columns={new_column_name: variable_name_with_unit}, inplace=True)\n",
    "\n",
    "print(ds_subset_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c802d1f5-cd5d-4f27-b5bd-d5068dc633a2",
   "metadata": {},
   "source": [
    "### 6. Plot the Data and Trend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a259d55-e871-46ac-8a25-70980f15603e",
   "metadata": {},
   "source": [
    "This block of code plots the variable column of the data frame against its time index.\n",
    "\n",
    "It also adds a trend line as an illustration of working with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f695a1-e94f-40a3-ac56-769e2da43843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the time index and column to plot\n",
    "time_list=pd.to_datetime(ds_subset_df.index)\n",
    "data_list = ds_subset_df.iloc[:,2]\n",
    "\n",
    "# Setup the plot\n",
    "plt.figure(figsize=(14, 8))  # Adjusting the size to provide more space for x-labels\n",
    "plt.plot(time_list, data_list, color='blue', linewidth=2, marker='o', markersize=6, markerfacecolor='red', markeredgewidth=1)\n",
    "plt.title(f'{variable_name} ({start_datetime[:]} - {end_datetime[:]})', fontsize=16)\n",
    "plt.xlabel(f'Date/time', fontsize=14)\n",
    "plt.ylabel(f'{variable_name} ({unit})', fontsize=14)\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Handling overlapping x-labels\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate labels and align them to the right\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(nbins=10))  # Show fewer labels to avoid overlap\n",
    "plt.gcf().autofmt_xdate()  # Automatically adjust x-label formatting for better spacing\n",
    "\n",
    "# Adding a trend line\n",
    "z = np.polyfit(range(len(time_list)), data_list, 1)\n",
    "p = np.poly1d(z)\n",
    "plt.plot(time_list, p(range(len(time_list))), color='black', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Saving the plot\n",
    "plt.savefig(f'{agg_interval}_{variable_code}_plot_for_point.png', dpi=800)\n",
    "\n",
    "# Displaying the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e3c688-f6b8-4a01-8486-95430322102e",
   "metadata": {},
   "source": [
    "### 7. Save the Data as a CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771cc1fc-ffb8-4599-887c-03809536959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "\n",
    "# Specify the file path where you want to save the CSV file\n",
    "file_path = f\"{variable_name}_at_a_point.csv\"\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "ds_subset_df.to_csv(file_path, index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
